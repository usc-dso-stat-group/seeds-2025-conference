<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="SEEDS Conference">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Sessions | SEEDS Conference</title>
</head>

<body>

    <div class="banner">
        <img src="assets/banner.jpg" alt="SEEDS Conference">
        <div class="top-left">
            <span class="title1">SEEDS</span><span class="title2">Conference</span> <span class="year">2025</span>
        </div>
        <div class="bottom-right">
            January 8-11, 2025 <br> University of Southern California, Los Angeles (CA)
        </div>
    </div>

    <style>
    .navigation {
        display: flex;
        justify-content: space-around;
        padding: 10px;
        background-color: #f8f9fa;
        border: 1px solid #ddd;
        border-radius: 5px;
    }
    .navigation a {
        text-decoration: none;
        padding: 10px 15px;
        color: #007bff;
        font-size: 24px; /* Increased font size */
        font-weight: 500; /* Medium weight for balance */
        border: 1px solid transparent;
        border-radius: 4px;
        transition: background-color 0.3s ease, color 0.3s ease;
    }
    .navigation a:hover {
        background-color: #007bff;
        color: white;
        border-color: #0056b3;
    }
    .navigation a.current {
        font-weight: bold;
        color: white;
        background-color: #007bff;
    }
</style>

<div class="navigation">
    <a title="Conference Home Page" href=".">Home</a>
    <a title="Register for the Conference" href="registration">Registration</a>
    <a title="Explore Short Courses" href="short courses">Short Courses</a>
    <a class="current" title="View Conference Sessions" href="sessions">Sessions</a>
    <a title="See the Full Schedule" href="schedule">Schedule</a>
    <a title="Find Venue Details" href="venue">Venue</a>
</div>

    <br>

    <a name=“keynote_presentations”>
    <h3>Keynote Presentations</h4>
    </a>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://fan.princeton.edu/">Jianqing Fan (Princeton University)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Spectral Ranking Inferences Based on General Multiway Comparisons
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: This paper studies the performance of the spectral method in the estimation and uncertainty quantification of the unobserved preference scores of compared entities in a general and more realistic setup. Specifically, the comparison graph consists of hyper-edges of possible heterogeneous sizes, and the number of comparisons can be as low as one for a given hyper-edge. Such a setting is pervasive in real applications, circumventing the need to specify the graph randomness and the restrictive homogeneous sampling assumption imposed in the commonly used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models. Furthermore, in scenarios where the BTL or PL models are appropriate, we unravel the relationship between the spectral estimator and the Maximum Likelihood Estimator (MLE). We discover that a two-step spectral method, where we apply the optimal weighting estimated from the equal weighting vanilla spectral method, can achieve the same asymptotic efficiency as the MLE. Given the asymptotic distributions of the estimated preference scores, we also introduce a comprehensive framework to carry out both one-sample and two-sample ranking inferences, applicable to both fixed and random graph settings. It is noteworthy that this is the first time effective two-sample rank testing methods have been proposed. Finally, we substantiate our findings via comprehensive numerical simulations and subsequently apply our developed methodologies to perform statistical inferences for statistical journals and movie rankings. (Joint work with Zhipeng Lou,  Weichen Wang, and Mengxin Yu)
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://www.hsph.harvard.edu/profile/xihong-lin/">Xihong Lin (Harvard University)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
              Navigate the Crossroad of Statistics, ML/AI and Domain Science
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
Abstract: The data science ecosystem encompasses data fairness, scalable statistical and ML/AI methods and tools, interpretable data analysis, and trustworthy decision-making. Rapid advancements in AI have revolutionized data utilization and enabled machines to learn from data more effectively. Statistics, as the science of learning from data while accounting for uncertainty, plays a pivotal role in addressing complex real-world problems and facilitating trustworthy decision-making. In this talk, I will discuss the challenges and opportunities as we navigate the crossroad of statistics and AI, including how to build an end-to-end scalable data science ecosystem, leverage AI/ML-prediction to empower statistical analysis of biobank data,  transfer inference for genetic association analysis,  build the whole genome variant functional annotation database and portal FAVOR and FAVOR-GPT,  and incorporate multi-faceted variant functional annotation to boost power of whole genome sequencing end-to-end analysis. This talk aims to ignite proactive and thought-provoking discussions, foster cross-disciplinary collaboration, and cultivate open-minded approaches to advance scientific discovery.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://www.statslab.cam.ac.uk/~rjs57/">Richard J. Samworth (University of Cambridge)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
            How should we do linear regression?
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
                Abstract: In the context of linear regression, we construct a data-driven convex loss function with respect to which empirical risk minimisation yields optimal asymptotic variance in the downstream estimation of the regression coefficients. Our semiparametric approach targets the best decreasing approximation of the derivative of the log-density of the noise distribution. At the population level, this fitting process is a nonparametric extension of score matching, corresponding to a log-concave projection of the noise distribution with respect to the Fisher divergence. The procedure is computationally efficient, and we prove that our procedure attains the minimal asymptotic covariance among all convex M-estimators. As an example of a non-log-concave setting, for Cauchy errors, the optimal convex loss function is Huber-like, and our procedure yields an asymptotic efficiency greater than 0.87 relative to the oracle maximum likelihood estimator of the regression coefficients that uses knowledge of this error distribution; in this sense, we obtain robustness without sacrificing much efficiency. 
            </td>
        </tr>
    </table>

    <h2>Invited Talks</h2>
    <p>
     <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://thomasberrett.github.io/">Thomas Berrett (University of Warwick)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Efficient estimation with incomplete data via generalised ANOVA decompositions
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: In this talk I will present recent work (https://arxiv.org/abs/2409.05729) on efficient estimation with incomplete data, covering problems arising in semi-supervised learning, data fusion and missing data literatures. Our task is to estimate simple mean functionals given access to a complete dataset that is supplemented by additional incomplete datasets. In particular, we aim to use the incomplete data to reduce the variance of the naive complete-case estimator, and to characterise the minimal asymptotic risk among all estimators. Results of this type exist for monotonic missingness structures, such as those arising in semi-supervised learning and longitudinal studies, but in this work we consider more general settings. We show that the optimal variance can be expressed through the minimal value of a quadratic optimisation problem over a function space, thus establishing a fundamental link between these estimation problems and the theory of generalised ANOVA decompositions. We introduce an estimator that is proved to attain this minimal risk and to be approximately normally distributed, and use this to construct confidence intervals.
        </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://www.maths.ed.ac.uk/~tcannings/About_Me.html">Timothy Cannings (University of Edinburgh)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Nonparametric classification with missing data
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: We introduce a new nonparametric framework for classification problems in the presence of missing data. The key aspect of our framework is that the regression function decomposes into an anova-type sum of orthogonal functions, of which some (or even many) may be zero. Working under a general missingness setting, which allows features to be missing not at random, our main goal is to derive the minimax rate for the excess risk in this problem. In addition to the decomposition property, the rate depends on parameters that control the tail behaviour of the marginal feature distributions, the smoothness of the regression function and a margin condition. The ambient data dimension does not appear in the minimax rate, which can therefore be faster than in the classical nonparametric setting. We further propose a new method, called the Hard-thresholding Anova Missing data (HAM) classifier, based on a careful combination of a k-nearest neighbour algorithm and a thresholding step. The HAM classifier attains the minimax rate up to polylogarithmic factors and numerical experiments further illustrate its utility.
            </td>
        </tr>
    </table>
      <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://www.gaolan.page/">Lan Gao (The University of Tennessee Knoxville)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             ARK: Robust Knockoffs Inference with Coupling
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: We investigate the robustness of the model-X knockoffs framework with respect to the misspecified or estimated feature distribution. We achieve such a goal by theoretically studying the feature selection performance of a practically implemented knockoffs algorithm, which we name as the approximate knockoffs (ARK) procedure, under the measures of the false discovery rate (FDR) and family wise error rate (FWER). The approximate knockoffs procedure differs from the model-X knockoffs procedure only in that the former uses the misspecified or estimated feature distribution. A key technique in our theoretical analyses is to couple the approximate knockoffs procedure with the model-X knockoffs procedure so that random variables in these two procedures can be close in realizations. We prove that if such coupled model-X knockoffs procedure exists, the approximate knockoffs procedure can achieve the asymptotic FDR or FWER control at the target level. We showcase three specific constructions of such coupled model-X knockoff variables, verifying their existence and justifying the robustness of the model-X knockoffs framework.
            </td>
        </tr>
    </table>

     <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://statistics.ucr.edu/image/dr-jose-angel-sanchez-gomez">Jose Angel Sanchez Gomez (UC Riverside)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Detecting hub variables in large Gaussian graphical models
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: In modern scientific applications, identifying small sets of variables in a dataset with a strong influence over the rest is often vital. For example, when studying the gene-expression levels of cancer patients, estimating the most influential genes can be a first step towards understanding underlying gene dynamics and proposing new treatments. A popular approach for representing variable influence is through a Gaussian graphical model (GGM), where each variable corresponds to a node, and a link between two nodes represents relationships among pairs of variables. In a GGM, influential variables correspond to nodes with a high degree of connectivity, also known as hub variables.
      In this talk, I share a new method for estimating hub variables in GGMs. To this end, we establish a connection between the presence of hubs in a GGM and the concentration of principal component vectors on the hub variables. We provide probabilistic guarantees of convergence for our method, even in high-dimensional data where the number of variables can be arbitrarily large. I will also discuss an application of this new method to a prostate cancer gene-expression dataset, through which we detect several hub genes with close connections to tumor development.
    </td>
    </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="http://jsb.ucla.edu/about-jingyi-jessica-li">Jingyi Jessica Li (UCLA)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             SyNPar: A Data-Preservation Framework for High-Power False Discovery Rate Control in High-Dimensional Variable Selection
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: Balancing false discovery rate (FDR) control and statistical power is a fundamental challenge in high-dimensional variable selection. Existing FDR control methods often perturb the original data, either by concatenating knockoff variables or splitting the data, which can compromise power. In this paper, we introduce SyNPar, a novel framework that controls the FDR in high-dimensional variable selection while preserving the integrity of the original data. SyNPar generates synthetic null data using an inference model under the null hypothesis and identifies false positives through a numerical analog of the likelihood ratio test. We provide rigorous theoretical guarantees for FDR control at any desired level and show that SyNPar achieves asymptotically optimal power. The framework is versatile, straightforward to implement, and applicable to a wide range of statistical models, including high-dimensional linear regression, generalized linear models (GLMs), Cox models, and Gaussian graphical models. Through extensive simulations and real-world data applications, we demonstrate that SyNPar consistently outperforms state-of-the-art methods, such as knockoff and data-splitting techniques, in terms of FDR control, statistical power, and computational efficiency.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://anna-neufeld.github.io/">Anna Neufeld (Williams College)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Data thinning to avoid double dipping
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: We refer to the practice of using the same data to fit and validate a model as double dipping. Problems arise when standard statistical procedures are applied in settings that involve double dipping. To circumvent the challenges associated with double dipping, one approach is to fit a model on one dataset, and then validate the model on another independent dataset. When we only have access to one dataset, we typically accomplish this via sample splitting. Unfortunately, in many unsupervised problems, sample splitting does not allow us to avoid double dipping. In this talk, we are motivated by unsupervised problems that arise in the analysis of single cell RNA sequencing data. We first propose Poisson count splitting, which splits a single observation drawn from a Poisson distribution into two independent components. We show that Poisson count splitting allows us to avoid double dipping in unsupervised settings. We next generalize the count splitting framework to a variety of distributions, and refer to the generalized framework as data thinning. Data thinning is a very general alternative to sample splitting that is useful far beyond the context of single-cell RNA sequencing data, and, unlike sample splitting, can be applied in both supervised and unsupervised settings.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://snigdha-panigrahi.netlify.app/">Snigdha Panigrahi (University of Michigan)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Cross-validation with antithetic gaussian randomization
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: In this talk, I will introduce a new method for performing cross-validation using “antithetic” Gaussian randomization variables. The randomization variables in our method are drawn from  an equicorrelated, degenerate normal distribution. Each pair of these randomization variables is maximally negatively correlated, which is why we describe this randomization scheme as “antithetic”.

Inspired by recent data-splitting techniques such as data-fission and data-thinning, the new cross-validation method is well-suited for problems where traditional sample splitting is infeasible. At the same time, even in scenarios where traditional sample splitting is feasible, our cross-validation method offers a computationally efficient alternative for estimating prediction error. By reducing the amount of randomization in the train data, our method achieves bias levels as small as the standard leave-one-out cross-validation, while requiring only a small number of train-test repetitions---potentially as few as two. A key advantage of our cross-validated estimator is its stable variance, which does not increase even as the bias from estimating the prediction function on the training data approaches zero. In both theory and simulations, we show that this desirable bias-variance property of our cross-validated estimator extends to a wide range of loss functions, including those commonly used in generalized linear models.

This is based on joint work with Sifan Liu and Jake Soloff. 
        </td>
        </tr>
    </table>

   <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://sites.google.com/view/npashley/">Nicole Pashley (Rutgers University)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Instrumental Variable Methods for Factorial Experiments with Complex Treatment Uptake
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: There is a well-established literature dealing with noncompliance in treatment-control designs within the potential-outcome framework for causal inference. However, generalizing to experiments with more than two treatment arms and noncompliance remains a challenge with limited exploration. The focus of this talk will be noncompliance in two-level factorial designs. The talk will discuss why this setting is so challenging, propose different assumptions to learn about relevant estimands, and explore identification and inference results under these assumptions.
            </td>
        </tr>
    </table>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://www.stat.uci.edu/faculty/annie-qu/">Annie Qu (UC Irvine)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Stage-Aware Learning for Dynamic Treatments
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: Recent advances in dynamic treatment regimes (DTRs) provide powerful optimal treatment searching algorithms, which are tailored to individuals’ specific needs and able to maximize their expected clinical benefits. However, existing algorithms could suffer from insufficient sample size under optimal treatments, especially for chronic diseases involving long stages of decision-making. To address these challenges, we propose a novel individualized learning method which estimates the DTR with a focus on prioritizing alignment between the observed treatment trajectory and the one obtained by the optimal regime across decision stages. By relaxing the restriction that the observed trajectory must be fully aligned with the optimal treatments, our approach substantially improves the sample efficiency and stability of inverse probability weighted based methods. In particular, the proposed learning scheme builds a more general framework which includes the popular outcome weighted learning framework as a special case of ours. Moreover, we introduce the notion of stage importance scores along with an attention mechanism to explicitly account for heterogeneity among decision stages. We establish the theoretical properties of the proposed approach, including the Fisher consistency and finite-sample performance bound. Empirically, we evaluate the proposed method in extensive simulated environments and a real case study for COVID-19 pandemic.
        </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://zhimeir.github.io/">Zhimei Ren (University of Pennsylvania)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Confidence on the Focal: Conformal Prediction with Selection-Conditional Coverage
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: Conformal prediction builds marginally valid prediction intervals that cover the unknown outcome of a randomly drawn new test point with a prescribed probability. However, a common scenario in practice is that, after seeing the data, practitioners decide which test unit(s) to focus on in a data-driven manner and seek for uncertainty quantification of the focal unit(s). In such cases, marginally valid conformal prediction intervals may not provide valid coverage for the focal unit(s) due to selection bias. In this talk, I will present a general framework for constructing a prediction set with finite-sample exact coverage conditional on the unit being selected by a given procedure. The general form of our method works for arbitrary selection rules that are invariant to the permutation of the calibration units, and generalizes Mondrian Conformal Prediction to multiple test units and non-equivariant classifiers. We then work out the computationally efficient implementation of our framework for a number of realistic selection rules, including top-K selection, optimization-based selection, selection based on conformal p-values, and selection based on properties of preliminary conformal prediction sets. The performance of our methods is demonstrated via applications in drug discovery and health risk prediction.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://ph.ucla.edu/about/faculty-staff-directory/damla-senturk">Damla Senturk (UCLA Department of Biostatistics)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Modeling intra-individual inter-trial EEG response variability in autism
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: Autism spectrum disorder (autism) is a prevalent neurodevelopmental condition
characterized by early emerging impairments in social behavior and communication.
EEG represents a powerful and non-invasive tool for examining functional brain differences
in autism. Recent EEG evidence suggests that greater intra-individual trial-to-trial
variability across EEG responses in stimulus-related tasks may characterize brain
differences in autism. Traditional analysis of EEG data largely focuses on mean trends
of the trial-averaged data, where trial-level analysis is rarely performed due to low neural
signal to noise ratio. We propose to use nonlinear (shape-invariant) mixed effects
(NLME) models to study intra-individual inter-trial EEG response variability using
trial-level EEG data. By providing more precise metrics of response variability, this
approach could enrich our understanding of neural disparities in autism and potentially
aid the identification of objective markers. The proposed multilevel NLME models
quantify variability in the signal’s interpretable and widely recognized features (e.g., latency
and amplitude) while also regularizing estimation based on noisy trial-level data.
Even though NLME models have been studied for more than three decades, existing
methods cannot scale up to large data sets. We propose computationally feasible estimation and inference methods via the use of a novel minorization-maximization (MM)
algorithm. Extensive simulations are conducted to show the efficacy of the proposed
procedures. Applications to data from a large national consortium find that children
with autism have larger intra-individual inter-trial variability in P1 latency in a visual
evoked potential (VEP) task, compared to their neurotypical peers.
            </td>
        </tr>
    </table>


    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://www.stat.ucdavis.edu/~wang/">Jane-Ling Wang (UC Davis)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Hypothesis testing for black-box survival model
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: Deep learning has become enormously popular in the analysis of complex data, including event time measurements with censoring. To date, deep survival methods have mainly focused on prediction. Such methods are scarcely used in matters of statistical inference such as hypothesis testing.  Due to their black-box nature, deep-learned outcomes lack interpretability which limits their use for decision-making in biomedical applications. Moreover, conventional tests fail to produce reliable type I errors due to the ability of deep neural networks to learn the data structure under the null hypothesis even if they search over the full space.  This talk provides testing methods for survival models and demonstrates its use in the nonparametric Cox model, where the nonparametric link function is modeled via a deep neural network.

To perform hypothesis testing, we utilize sample splitting and cross-fitting procedures to get neural network estimators and construct the test statistic. These procedures enable us to propose a new significance test to examine the association of certain covariates with event times. We show that our test statistic converges to a normal distribution under the null hypothesis and establish its consistency, in terms of the Type II error, under the alternative hypothesis. Numerical simulations and a real data application demonstrate the usefulness of the proposed test.
        </td>
        </tr>
    </table>


    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://pages.stat.wisc.edu/~miaoyan/">Miaoyan Wang (University of Wisconsin-Madison, Visiting Stanford University)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Application and Methods for Structured Tensor Learning
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: High-order tensor datasets pose common challenges in applications such as recommendation systems, neuroimaging, and social networks. In this work, we introduce two approaches for learning with structured tensors: tensor block models for higher-order clustering and sign-series models for tensor denoising. These approaches provide a lens into the unique properties of tensor analysis. We establish statistical and computational efficiency results for each method. Additionally, we present polynomial-time algorithms with guaranteed efficiency. The effectiveness of our methods is demonstrated through applications to neuroimaging data analysis and social network analysis. 
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/yu/">Yi Yu (University of Warwick)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             Private distributed functional data analysis
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: In this talk, we study private distributed functional data analysis problems, for both mean estimation and varying coefficient model estimation.  We show the interplay of federated, central and user-level differential privacy notions.  Our results show a number of interesting phase transition phenomena, from sparse to dense and from non-private to various private notions.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="https://www.yuhuazhu.org/">Yuhua Zhu (University of California, Los Angeles)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             A PDE-based model-free algorithm for Continuous-time Reinforcement Learning
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: This talk addresses the problem of continuous-time reinforcement learning (RL). When the underlying dynamics remain unknown and only discrete-time observations are available, how can we effectively conduct policy evaluation and policy iteration? We first highlight that while model-free RL algorithms are straightforward to implement, they are often not a reliable approximation of the true value function. On the other hand, model-based PDE approaches are more accurate, but the inverse problem is not easy to solve. To bridge this gap, we introduce a new Bellman equation, PhiBE, which integrates discrete-time information into a PDE formulation. PhiBE allows us to skip the identification of the dynamics and directly evaluate the value function using discrete-time data. Additionally, it offers a more accurate approximation of the true value function, especially in scenarios where the underlying dynamics change slowly. Moreover, we extend PhiBE to higher orders, providing increasingly accurate approximations.
            </td>
        </tr>
    </table>
    
   <table>
        <tr>
            <td class="date" rowspan="2">
            </td>
            <td class="title">
                <a href="http://jrzubizarreta.com/">José R. Zubizarreta (Harvard University)</a>
            </td>
        </tr>
        <tr>
            <td class="speaker">
             An Anatomy of Event Studies: Hypothetical Experiments, Exact Decomposition, and Weighting Diagnostics
            </td>
        </tr>
            <td class="date" rowspan="2">

            </td>
        <tr>
            <td class="abstract">
              Abstract: In recent decades, event studies have emerged as a central methodology in health and social research for evaluating the causal effects of staggered interventions. In this paper, we analyze event studies from experimental design principles for observational studies, with a focus on information borrowing across measurements. We develop robust weighting estimators that increasingly use more information across units and time periods, justified by increasingly stronger assumptions on the treatment assignment and potential outcomes mechanisms. As a particular case of this approach, we offer a novel decomposition of the classical dynamic two-way fixed effects (TWFE) regression estimator for event studies. Our decomposition is expressed in closed form and reveals in finite samples the hypothetical experiment that TWFE regression adjustments approximate. This decomposition offers insights into how standard regression estimators borrow information across different units and times, clarifying and supplementing the notion of forbidden comparison noted in the literature. The proposed approach enables the generalization of treatment effect estimates to a target population and offers new diagnostics for event studies, including covariate balance, sign reversal, effective sample size, and the contribution of each observation to the analysis. We also provide visualization tools for event studies and illustrate them in a case study of the impact of divorce reforms on female suicide.
        </td>
        </tr>
    </table>


    </p>



<footer>
    &copy; Conference Organizers
    &nbsp;|&nbsp; Design by <a href="https://github.com/mikepierce">Mike Pierce</a>
</footer>

</body>
</html>
